{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db64ff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DESCRIPTION: \n",
    "A program to concurrently download subsets from ImageNet using ImageNet API.\n",
    "To run the script correctly, please modify the arguments in this cell then run all cells.\n",
    "\n",
    "ARGUMENT LIST:\n",
    "scrape_only_flickr:        Set to True if only want images from Flickr.\n",
    "number_of_classes:         The number of classes to be randomly picking for downloading.\n",
    "images_per_class:          How many images to be downloaded for each class.\n",
    "data_root:                 The dir for storing the downloaded images.\n",
    "use_class_list:            Whether to use customized class list instead of random picking.\n",
    "class_list:                A list of class to be downloaded. Please put the labels of the \n",
    "                           classes (e.g. n12345678...) instead of the class names (e.g. \n",
    "                           person, dog...) in type str in the list. For the full list of \n",
    "                           label-name pairs, please refer to the ./imagenet_class_info.json\n",
    "                           file in this directoy. If you want to get the keywords of each\n",
    "                           class, please refer to the ./words.txt file in the directoy.\n",
    "multiprocessing_workers:   How many threads to process the request simultaneousy.\n",
    "'''\n",
    "scrape_only_flickr = False\n",
    "number_of_classes = 156\n",
    "images_per_class = 5\n",
    "data_root = 'data'\n",
    "use_class_list = False\n",
    "use_subdir = True\n",
    "class_list = ['n00007846']\n",
    "multiprocessing_workers = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b0678d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages and components\n",
    "import os, requests, json, time\n",
    "import numpy as np\n",
    "from multiprocessing import Pool, Process, Value, Lock\n",
    "from requests.exceptions import ConnectionError, ReadTimeout, TooManyRedirects, MissingSchema, InvalidURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30f2556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for adding arguments\n",
    "class Args:\n",
    "    def __init__(self, \n",
    "                 scrape_only_flickr, \n",
    "                 number_of_classes, \n",
    "                 images_per_class, \n",
    "                 data_root, \n",
    "                 use_class_list, \n",
    "                 class_list, \n",
    "                 use_subdir,\n",
    "                 multiprocessing_workers):\n",
    "        self.scrape_only_flickr = scrape_only_flickr\n",
    "        self.number_of_classes = number_of_classes\n",
    "        self.images_per_class = images_per_class\n",
    "        self.data_root = data_root\n",
    "        self.use_class_list = use_class_list\n",
    "        self.class_list = class_list\n",
    "        self.multiprocessing_workers = multiprocessing_workers\n",
    "        self.use_subdir = use_subdir\n",
    "        self.checkArgs()\n",
    "    \n",
    "    def checkArgs(self):\n",
    "        if type(self.scrape_only_flickr) is not bool:\n",
    "            raise TypeError('Use boolean value for scrape_only_flickr')\n",
    "        if type(self.number_of_classes) is not int:\n",
    "            raise TypeError('Use integers for number_of_classes')\n",
    "        if type(self.images_per_class) is not int:\n",
    "            raise TypeError('Use integers for images_per_class')\n",
    "        if type(self.data_root) is not str:\n",
    "            raise TypeError('Use str for data_root')\n",
    "        if type(self.use_class_list) is not bool:\n",
    "            raise TypeError('Use boolean value for use_class_list')\n",
    "        if type(self.class_list) is not list:\n",
    "            raise TypeError('Use list for class_list')\n",
    "        if type(self.use_subdir) is not bool:\n",
    "            raise TypeError('Use boolean value for use_subdir')\n",
    "        if type(multiprocessing_workers) is not int:\n",
    "            raise TypeError('Use int for multiprocessing workers')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "994af784",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(scrape_only_flickr,\n",
    "           number_of_classes,\n",
    "           images_per_class,\n",
    "           data_root,\n",
    "           use_class_list,\n",
    "           class_list,\n",
    "           use_subdir,\n",
    "           multiprocessing_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbcedc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if data_root is valid\n",
    "if len(args.data_root) == 0:\n",
    "    raise Exception(\"-data_root is required to run downloader!\")\n",
    "    \n",
    "if not os.path.isdir(args.data_root):\n",
    "    raise Exception(f'folder {args.data_root} does not exist! please provide existing folder in -data_root arg!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c61fc08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/xinye/Library/CloudStorage/OneDrive-Personal/education/M23_CMU/01_dataset/01_imageNet/ImageNet-Datasets-Downloader/00_ImageNet\n",
      "Picked the following clases:\n",
      "['tachymeter', 'acquaintance', 'borage', 'ring-necked parakeet', 'veal cordon bleu', 'votary', 'New World sparrow', 'kidney fern', 'bearberry', 'cape forget-me-not', 'junior middleweight', 'yam', 'trogon', 'dinner jacket', 'tube', 'bunghole', 'concept album', 'ashcake', 'licenser', 'thermopile', 'jig', 'insurgent', 'radiobiologist', 'air search radar', 'sitar player', 'confectionery', 'clingfish', 'corn', 'rib', 'Moreton Bay tulipwood', 'negative magnetic pole', 'teak', 'giant chinkapin', 'structural member', 'red shrubby penstemon', 'Turkish towel', 'constructivist', 'bowline', 'white yam', 'queen', 'portrait lens', 'gorgonian', 'gift wrapping', 'pond-scum parasite', 'common horehound', 'extern', 'pyrograph', 'daybook', 'wire cloth', 'tattoo', 'head', 'Bernese mountain dog', 'arbovirus', 'basketball', 'wayfaring tree', 'devisor', 'Brazilian pepper tree', 'handwheel', 'June beetle', 'safety razor', 'cairn', 'bluefish', 'Neolentinus ponderosus', 'vibist', 'serin', 'nicad', 'cord', 'overhead projector', 'house', 'athletic supporter', 'spring water', 'gun carriage', 'strawflower', 'squash', 'European bream', 'flowering almond', 'boffin', 'bobolink', 'wassail', \"baby's breath\", 'tiger moth', 'phloem', 'balker', 'tallyman', 'shirtwaist', 'platform', 'black vulture', 'barnacle', 'sampan', 'spirit lamp', 'Texan', 'soft tree fern', 'box coat', 'lodestone', 'glass sponge', 'hispid pocket mouse', 'hamburger bun', 'flipper', 'zigzag goldenrod', 'avens', 'Nuttall oak', 'Alpine besseya', 'pop tent', 'lock', 'adult', 'juror', 'leak', 'alpaca', 'walleye', 'automobile horn', 'closed circuit', 'slug', 'vehicle', 'locomotive', 'papillon', 'aerosol', 'traverser', 'sour cherry', 'buffalo fish', 'chow', 'jaguarundi', 'radiator', 'congress boot', 'redneck', 'Angora', 'love-in-winter', 'human botfly', 'boy wonder', 'luggage compartment', 'integrator', 'hellebore', 'life jacket', 'echinocactus', 'prima ballerina', 'rewa-rewa', 'Omani', 'ice milk', 'root climber', 'meadow rue', 'clock radio', 'cabinet', 'Gibson girl', 'camper', 'azalea', 'achimenes', 'home plate', 'water violet', 'artwork', 'Lao', 'AND circuit', 'corvine bird', 'pill bug', 'shrimper', 'feijoa', 'stainer', 'meat safe']\n"
     ]
    }
   ],
   "source": [
    "# get imagenet class info and the names of the classes to download\n",
    "current_folder = os.path.realpath(os.path.abspath(''))\n",
    "print(current_folder)\n",
    "class_info_json_filename = 'imagenet_class_info.json'\n",
    "class_info_json_filepath = os.path.join(current_folder, class_info_json_filename)\n",
    "class_info_dict = dict()\n",
    "\n",
    "with open(class_info_json_filepath) as class_info_json_f:\n",
    "    class_info_dict = json.load(class_info_json_f)\n",
    "    \n",
    "classes_to_scrape = []\n",
    "\n",
    "if args.use_class_list:\n",
    "   for item in args.class_list:\n",
    "       classes_to_scrape.append(item)\n",
    "       if item not in class_info_dict:\n",
    "           raise Exception(f'Class {item} not found in ImageNete')\n",
    "\n",
    "else:\n",
    "    potential_class_pool = []\n",
    "    for key, val in class_info_dict.items():\n",
    "        if args.scrape_only_flickr:\n",
    "            if int(val['flickr_img_url_count']) * 0.9 > args.images_per_class:\n",
    "                potential_class_pool.append(key)\n",
    "        else:\n",
    "            if int(val['img_url_count']) * 0.8 > args.images_per_class:\n",
    "                potential_class_pool.append(key)\n",
    "\n",
    "    if (len(potential_class_pool) < args.number_of_classes):\n",
    "        raise Exception(f'''With {args.images_per_class} images per class there are \n",
    "                           {len(potential_class_pool)} to choose from.\n",
    "                           Decrease number of classes or decrease images per class.''')\n",
    "\n",
    "    picked_classes_idxes = np.random.choice(len(potential_class_pool), args.number_of_classes, replace = False)\n",
    "\n",
    "    for idx in picked_classes_idxes:\n",
    "        classes_to_scrape.append(potential_class_pool[idx])\n",
    "\n",
    "\n",
    "print(\"Picked the following clases:\")\n",
    "print([ class_info_dict[class_wnid]['class_name'] for class_wnid in classes_to_scrape ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4113a7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dir for storing images\n",
    "imagenet_images_folder = os.path.join(args.data_root, 'imagenet_images')\n",
    "if not os.path.isdir(imagenet_images_folder):\n",
    "    os.mkdir(imagenet_images_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53e2e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a class for storing downloading stats\n",
    "class MultiStats():\n",
    "    def __init__(self):\n",
    "\n",
    "        self.lock = Lock()\n",
    "\n",
    "        self.stats = dict(\n",
    "            all=dict(\n",
    "                tried=Value('d', 0),\n",
    "                success=Value('d',0),\n",
    "                time_spent=Value('d',0),\n",
    "            ),\n",
    "            is_flickr=dict(\n",
    "                tried=Value('d', 0),\n",
    "                success=Value('d',0),\n",
    "                time_spent=Value('d',0),\n",
    "            ),\n",
    "            not_flickr=dict(\n",
    "                tried=Value('d', 0),\n",
    "                success=Value('d', 0),\n",
    "                time_spent=Value('d', 0),\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    def inc(self, cls, stat, val):\n",
    "        with self.lock:\n",
    "            self.stats[cls][stat].value += val\n",
    "\n",
    "    def get(self, cls, stat):\n",
    "        with self.lock:\n",
    "            ret = self.stats[cls][stat].value\n",
    "        return ret\n",
    "\n",
    "multi_stats = MultiStats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e98d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lock = Lock()\n",
    "url_tries = Value('d', 0)\n",
    "scraping_t_start = Value('d', time.time())\n",
    "class_folder = ''\n",
    "class_images = Value('d', 0)\n",
    "\n",
    "IMAGENET_API_WNID_TO_URLS = lambda wnid: f'http://www.image-net.org/api/imagenet.synset.geturls?wnid={wnid}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d78134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(cls, print_func):\n",
    "    global scraping_t_start\n",
    "    actual_all_time_spent = time.time() - scraping_t_start.value\n",
    "    processes_all_time_spent = multi_stats.get('all', 'time_spent')\n",
    "\n",
    "    if processes_all_time_spent == 0:\n",
    "        actual_processes_ratio = 1.0\n",
    "    else:\n",
    "        actual_processes_ratio = actual_all_time_spent / processes_all_time_spent\n",
    "\n",
    "    #print(f\"actual all time: {actual_all_time_spent} proc all time {processes_all_time_spent}\")\n",
    "\n",
    "    print_func(f'STATS For class {cls}:')\n",
    "    print_func(f' tried {multi_stats.get(cls, \"tried\")} urls with'\n",
    "               f' {multi_stats.get(cls, \"success\")} successes')\n",
    "\n",
    "    if multi_stats.get(cls, \"tried\") > 0:\n",
    "        print_func(f'{100.0 * multi_stats.get(cls, \"success\")/multi_stats.get(cls, \"tried\")}% success rate for {cls} urls ')\n",
    "    if multi_stats.get(cls, \"success\") > 0:\n",
    "        print_func(f'{multi_stats.get(cls,\"time_spent\") * actual_processes_ratio / multi_stats.get(cls,\"success\")} seconds spent per {cls} succesful image download')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c9ee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(img_url):\n",
    "\n",
    "    print(f'Processing {img_url}')\n",
    "\n",
    "    #time.sleep(3)\n",
    "    \n",
    "    global lock, url_tries, class_folder, class_images\n",
    "\n",
    "    if len(img_url) <= 1:\n",
    "        return\n",
    "\n",
    "\n",
    "    cls_imgs = 0\n",
    "    with lock:\n",
    "        cls_imgs = class_images.value\n",
    "\n",
    "    if cls_imgs >= args.images_per_class:\n",
    "        return\n",
    "\n",
    "    cls = ''\n",
    "\n",
    "    if 'flickr' in img_url:\n",
    "        cls = 'is_flickr'\n",
    "    else:\n",
    "        cls = 'not_flickr'\n",
    "        if args.scrape_only_flickr:\n",
    "            return\n",
    "\n",
    "    t_start = time.time()\n",
    "\n",
    "    def finish(status):\n",
    "        t_spent = time.time() - t_start\n",
    "        multi_stats.inc(cls, 'time_spent', t_spent)\n",
    "        multi_stats.inc('all', 'time_spent', t_spent)\n",
    "\n",
    "        multi_stats.inc(cls,'tried', 1)\n",
    "        multi_stats.inc('all', 'tried', 1)\n",
    "\n",
    "        if status == 'success':\n",
    "            multi_stats.inc(cls,'success', 1)\n",
    "            multi_stats.inc('all', 'success', 1)\n",
    "\n",
    "        elif status == 'failure':\n",
    "            pass\n",
    "        else:\n",
    "            raise Exception(f'No such status {status}!!')\n",
    "        return\n",
    "\n",
    "\n",
    "    with lock:\n",
    "        url_tries.value += 1\n",
    "        if url_tries.value % 250 == 0:\n",
    "            print(f'\\nScraping stats:')\n",
    "            print_stats('is_flickr', print)\n",
    "            print_stats('not_flickr', print)\n",
    "            print_stats('all', print)\n",
    "\n",
    "    try:\n",
    "        img_resp = requests.get(img_url, timeout = 1)\n",
    "    except ConnectionError:\n",
    "        return finish('failure')\n",
    "    except ReadTimeout:\n",
    "        return finish('failure')\n",
    "    except TooManyRedirects:\n",
    "        return finish('failure')\n",
    "    except MissingSchema:\n",
    "        return finish('failure')\n",
    "    except InvalidURL:\n",
    "        return finish('failure')\n",
    "\n",
    "    if not 'content-type' in img_resp.headers:\n",
    "        return finish('failure')\n",
    "\n",
    "    if not 'image' in img_resp.headers['content-type']:\n",
    "        return finish('failure')\n",
    "\n",
    "    if (len(img_resp.content) < 1000):\n",
    "        return finish('failure')\n",
    "\n",
    "    img_name = img_url.split('/')[-1]\n",
    "    img_name = img_name.split(\"?\")[0]\n",
    "\n",
    "    if (len(img_name) <= 1):\n",
    "        return finish('failure')\n",
    "\n",
    "    img_file_path = os.path.join(class_folder, img_name)\n",
    "\n",
    "    with open(img_file_path, 'wb') as img_f:\n",
    "        img_f.write(img_resp.content)\n",
    "\n",
    "        with lock:\n",
    "            class_images.value += 1\n",
    "\n",
    "        return finish('success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deab27fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(scrape_only_flickr,\n",
    "           number_of_classes,\n",
    "           images_per_class,\n",
    "           data_root,\n",
    "           use_class_list,\n",
    "           class_list,\n",
    "           use_subdir,\n",
    "           multiprocessing_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21819dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal multiprocessing.Pool will not work with interactive python tools\n",
    "# but this multiprocess works\n",
    "# !pip install multiprocess\n",
    "import multiprocess as mp\n",
    "\n",
    "for class_wnid in classes_to_scrape:\n",
    "\n",
    "    class_name = class_info_dict[class_wnid][\"class_name\"]\n",
    "    print(f'Scraping images for class \\\"{class_name}\\\"')\n",
    "    url_urls = IMAGENET_API_WNID_TO_URLS(class_wnid)\n",
    "\n",
    "    time.sleep(0.05)\n",
    "    resp = requests.get(url_urls)\n",
    "    \n",
    "    if args.use_subdir:\n",
    "        class_folder = os.path.join(imagenet_images_folder, class_name)\n",
    "    else:\n",
    "        class_folder = imagenet_images_folder\n",
    "        \n",
    "    if not os.path.exists(class_folder):\n",
    "        os.mkdir(class_folder)\n",
    "\n",
    "    class_images.value = 0\n",
    "\n",
    "    urls = [url.decode('utf-8') for url in resp.content.splitlines()]\n",
    "\n",
    "    #for url in  urls:\n",
    "    #    get_image(url)\n",
    "\n",
    "    print(f\"Multiprocessing workers: {args.multiprocessing_workers}\")\n",
    "    \n",
    "    with mp.Pool(processes=args.multiprocessing_workers) as p:\n",
    "        p.map(get_image,urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baaae8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733a0952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
